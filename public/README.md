# Resk Security

![Resk Security Logo](https://resk.fr/wp-content/uploads/2023/06/resk-logo.png)  
*(Source: resk.fr)*

**Securing the Future of AI Applications**

Resk Security is a French-based organization dedicated to advancing **AI security** through open-source tools and research. We focus on protecting Large Language Model (LLM) integrations from common vulnerabilities such as **prompt injections**, data leaks, PII exposure, and malicious content generation.

Our mission is to provide developers with robust, easy-to-integrate security layers that ensure safe, compliant, and performant AI applications ‚Äî without compromising on usability or speed.

üåç **Location:** France  
üåê **Website:** [resk.fr](http://resk.fr)  
üìß **Email:** contact@resk.fr  
üíº **LinkedIn:** [Resk on LinkedIn](https://www.linkedin.com/company/resk)

## Our Objectives

- **Enhance LLM Security:** Build comprehensive toolkits to defend against emerging threats in AI systems.
- **Promote Open-Source Collaboration:** Share high-quality, well-documented libraries to help the community secure AI deployments.
- **Support Multi-Language & Multi-Provider Ecosystems:** Provide solutions for Python, TypeScript/JavaScript, and more, compatible with major LLM providers (OpenAI, Anthropic, Cohere, etc.).
- **Optimize Performance & Cost:** Integrate intelligent caching, monitoring, and efficient algorithms to reduce API costs and latency.
- **Foster Research & Innovation:** Develop proof-of-concepts, logits processors, and advanced security features grounded in the latest AI security research.

## Featured Projects

Here are our key open-source repositories:

### [Resk-LLM](https://github.com/Resk-Security/Resk-LLM) ‚≠ê 13
A robust **Python** library for securing LLM API interactions. It adds a protective layer against prompt injections, PII leaks, malicious URLs, and more. Supports multiple providers and includes advanced features like context management, monitoring, and caching.  
*Ideal for Python-based AI applications.*

### [resk-llm-ts](https://github.com/Resk-Security/resk-llm-ts) ‚≠ê 7
A comprehensive **TypeScript/JavaScript** security toolkit for LLM integrations. Wraps OpenAI-compatible APIs with built-in defenses against prompt injections, data leakage, and content moderation.  
*Perfect for web, Node.js, or frontend AI apps.*

### [resk-mcp](https://github.com/Resk-Security/resk-mcp)
An enhanced security and management layer for the **Model Context Protocol (MCP)** Python SDK. Adds monitoring, context handling, and robust protections for advanced LLM workflows.

### [resk-caching](https://github.com/Resk-Security/resk-caching) ‚≠ê 7
A high-performance **Bun-based** backend for secure caching of LLM responses using vector databases. Reduces API costs through semantic similarity matching, with built-in security, observability, and real-time distribution.

### Other Projects
- [resk-logits](https://github.com/Resk-Security/resk-logits): A logits processor for "shadow banning" dangerous content during LLM generation.
- [backdoor-poc](https://github.com/Resk-Security/backdoor-poc): Proof-of-concept explorations in LLM security.
- [resk-android](https://github.com/Resk-Security/resk-android): Emerging security tools for Android AI applications (Kotlin).
- And more experimental repositories ‚Äî check them out!

## Get Involved
We welcome contributions, feedback, and stars! üöÄ  
If you're building with LLMs and care about security, try our tools today:
```bash
pip install resk-llm
```
or
```bash
npm install resk-llm-ts
```

Follow us for updates on new releases, security research, and AI best practices.

**Together, let's make AI safer for everyone.** üîí

#AISecurity #LLM #PromptInjection #OpenSource #Python #TypeScript
